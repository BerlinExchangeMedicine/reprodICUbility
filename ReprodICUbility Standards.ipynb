{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978ade2c-de01-4a46-af39-4b35d9214a08",
   "metadata": {},
   "source": [
    "# ReprodICUbility: Open Science and Coding Guidelines\n",
    "Welcome to ReprodICUbility! It is a pleasure to have you with us.\n",
    "In this Notebook, we want to provide a guide for implementing best practices in two critical areas: **Open Science** and **Coding Guidelines**.\n",
    "\n",
    "<u>**Open Science**</u>  \n",
    "As members of the Student Network of Open Science, adhering to open science principles is one of our highest priorities and this Notebook will help operationalize these principles. It aims to offer steps to integrate the at times abstract and lofty ideals of open science into our workflows in a concrete, pragmatic manner.\n",
    "\n",
    "<u>**Coding Guidelines**</u>  \n",
    "Collaborative work is at the core of our project, making standardized coding practices essential. This section will outline guidelines designed to streamline collaboration by ensuring uniformity in code across teams and throughout the project. Additionally, it will provide recommendations for enhancing code readability and structure.\n",
    "\n",
    "\n",
    "Together, these guidelines will support our shared goal of developing a robust and reproducible open reproduction pipeline as a team effort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2a01df-5798-4260-b904-0537fb381088",
   "metadata": {},
   "source": [
    "## <u>**[I] Open Science**</u>\n",
    "\n",
    "### <u>0. Open Ignorance</u>\n",
    "- **Principle**:\n",
    "    - This is a note for our collaboration rather than for the reproduction process itself.\n",
    "    - ReprodICUbility is a large, fast-paced project where diverse backgrounds meet. Naturally, this will lead to questions and uncertainties.\n",
    "- **Practice:**\n",
    "    - _Openly ask every question you have_: a willingness to learn is far more valuable here than trying to appear omniscient!\n",
    "        - If you don’t understand something after paying attention, chances are that half of your collaborators are in the same boat.\n",
    "    - _Share helpful resources_ or explanations whenever you find answers to your questions.\n",
    "    - Encourage a culture where asking for clarification is seen as a contribution to collective understanding.\n",
    "\n",
    "### <u>1. Accountability</u>\n",
    "- **Principle**:\n",
    "    - Effective collaboration and appropriate crediting require documentation of your contributions to the project.\n",
    "    - Open science starts with transparency among ourselves, not just with what we present the public at the end.\n",
    "    - It is remarkable how much it speeds up team efforts to know precisely whom to ask about a specific decision that was made.\n",
    "        - “What does this variable mean? What statistical assumption is being tested here? Who decided on this or that approach? . . .”\n",
    "- **Practice**:\n",
    "    - _Annotate_ scripts and documents when you make significant alterations or decisions, along with the rationales behind them.\n",
    "    - Maintain a changelog in our shared documents to track who made which changes and why.\n",
    "        - Suggestion: Set up brief but regular _documentation sprints_ where teams review and update project records.\n",
    "    - Regular _check-ins with other teams_: Engage in mutual reviews and exchanges of ideas.\n",
    "        - Articulating your approaches helps identify inconsistencies, often even before others point them out.\n",
    "\n",
    "### <u>2. Transparency</u>\n",
    "- **Principle:**\n",
    "    - This may be the heart of classic open science: making all aspects of research accessible, including methods, data, protocols, and results, to enable scrutiny and reuse.\n",
    "- **Practice:**\n",
    "    - _Citation_: Provide full references for all external information, whether from papers, textbooks, or other resources.\n",
    "    - _AI_: Nowadays, most of us use AI in some way. Documenting exactly how and were it was used it, thus, also part of open science practice.\n",
    "    - _Findings_: Report all findings, regardless of whether they align with expectations or are appealing — do not filter evidence.\n",
    "    - _Alternatives_: Acknowledge that there is no single way to build a pipeline as we plan, and record any statistical disputes, alternative methods, and assumptions discussed within the team. Be transparent about which decisions were made, which alternatives were omitted — and why.\n",
    "    - _Platforms_: Use the shared, open-access platforms we provide for storing and sharing data, code, and documentation, ensuring that all team members and external collaborators have access.\n",
    "\n",
    "\n",
    "<u>**Beyond**</u>\n",
    "Fortunately, much of the ReprodICUbility infrastructure inherently supports open science. Using the resources we provide integrates many of the more basic open science practices by design. Here, too, _always ask questions_ if anything about the digital architecture is unclear, unintuitive or posits a hurdle to your work. \n",
    "And after all: Reproducibility itself is one of the major principles of open science :) \n",
    "\n",
    "Thank you for your contribution! <3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655bf400-157d-422e-8fa4-511a2da2d344",
   "metadata": {},
   "source": [
    "Interesting Resources:\n",
    "- Open Science Collaboration. PSYCHOLOGY. Estimating the reproducibility of psychological science. Science. 2015 Aug 28;349(6251):aac4716. doi: 10.1126/science.aac4716. PMID: 26315443.\n",
    "- National Academies of Sciences, Engineering, and Medicine; Policy and Global Affairs; Board on Research Data and Information; Committee on Toward an Open Science Enterprise. Open Science by Design: Realizing a Vision for 21st Century Research. Washington (DC): National Academies Press (US); 2018 Jul 17. PMID: 30212065.\n",
    "- Grant S, Mayo-Wilson E, Kianersi S, Naaman K, Henschel B. Open Science Standards at Journals that Inform Evidence-Based Policy. Prev Sci. 2023 Oct;24(7):1275-1291. doi: 10.1007/s11121-023-01543-z. Epub 2023 May 13. PMID: 37178346."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f84e7b-186c-461f-8b10-907c2003e9b0",
   "metadata": {},
   "source": [
    "## <u>**[II] Coding Guidelines**</u>\n",
    "\n",
    "The Coding Guidelines will follow two principles: Standardization and Readability. These two obviously go hand in hand in many regards.\n",
    "\n",
    "**Standardization** simply refers to norms we want to lay down at the beginning of the project. These concern variable and function names, code structure, logging, etc. These standards may seem arbitrary at times — and they are! But we need to standardize format somehow to ensure uniformity across teams and across time, otherwise this whole thing will become a mess very quickly. Thus, we would kindly ask you to adhere to these standards as best as you can.\n",
    "\n",
    "**Readability** involves general recommendations for streamlining teamwork throughout the project. We all sometimes approach coding nonchalantly with an attitude of: “Who else needs to read this?”. But for our project, readability is key. As a shorthand, you can ask yourself: If you lost your memory of the past days, could you understand your own code from scratch? How much time and effort would that take? \n",
    "\n",
    "Let’s dive in!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ccaa8-59ff-4396-b575-54f538f28a94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <u>1. **Naming Variables and Functions**</u>\n",
    "\n",
    "- _ReprodICUbility_: We have noticed in the preparation for this project that the name “ReprodICUbility” is quickly misspelled, which is why we will consistently use its short form _**repro**_ when we need to refer to it in code.\n",
    "- _Necessity_: It is a prominent mistake to optimize something that shouldn’t even exist → Do you really need this new variable/function?\n",
    "    - Whenever a new name or operation is introduced in code, explain its purpose and background in the larger context (see commenting). \n",
    "- _Case Type_: We've decided to exclusively use _**snake_case**_ (i.e., sub-names separated by underscores) instead of camelCase or PascalCase. This is one of these arbitrary standards specified above - it is purely an aesthetic formality that we want to lay down for consistency.\n",
    "- _Clarity_: Try to be *too* explicit (because you can actually never be too explicit). Make names longer rather than shorter and a bit more obvious than you think necessary at the time. For example:\n",
    "    - Avoid abbreviations.\n",
    "    - Put units in variable names where useful (e.g., `missing_variables_percentage_decimal_notation` or `missing_variables_percentage_percentage_notation`; `delay_time_seconds` or `delay_time_minutes`).\n",
    "\n",
    "As an example, check out this snippet of code. Can you figure out what it is for? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ef69889-5aad-4f12-bb54-bfa00e355216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  M        V\n",
      "T-s 4.242251\n",
      "P-v 0.000206\n",
      "C-d 0.774526\n",
      " Pw 0.983744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.power import TTestPower\n",
    "\n",
    "def pdt(data_b, data_a, a=0.05):\n",
    "    t_s, p_v = stats.ttest_rel(data_b, data_a)\n",
    "    m_d = np.mean(data_b - data_a)\n",
    "    s_d = np.std(data_b - data_a, ddof=1)\n",
    "    c_d = m_d / s_d\n",
    "    e_s = np.abs(c_d)\n",
    "    n = len(data_b)\n",
    "    pw_a = TTestPower()\n",
    "    pw = pw_a.solve_power(effect_size=e_s, nobs=n, alpha=a, alternative='two-sided')\n",
    "    r = pd.DataFrame({\n",
    "        'M': ['T-s', 'P-v', 'C-d', 'Pw'],\n",
    "        'V': [t_s, p_v, c_d, pw]\n",
    "    })\n",
    "    return r\n",
    "\n",
    "def mn():\n",
    "    np.random.seed(42)\n",
    "    d_b = np.random.normal(100, 10, 30)\n",
    "    d_a = d_b + np.random.normal(-3, 5, 30)\n",
    "    r = pdt(d_b, d_a)\n",
    "    print(r.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c594cd99-e67b-4636-a117-09e116b9af16",
   "metadata": {},
   "source": [
    "I don't know about you, but it would take me much longer than necessary to understand what is going on here, although this is actually a very basic statistical test. This is simply a dependent sample t-test on some randomly generated data in the main function. The abbreviations, however, can make it hard to understand exactly what is happening. \n",
    "We suggest that in the context of ReprodICUbility you be as explicit in your naming of variables and functions as possible. \n",
    "Look at this second example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "733c4b65-2f89-4538-9a69-f36fb9357739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric    Value\n",
      "            T-statistic 4.242251\n",
      "                P-value 0.000206\n",
      "Effect Size (Cohen's d) 0.774526\n",
      "      Statistical Power 0.983744\n"
     ]
    }
   ],
   "source": [
    "def perform_dependent_sample_ttest(data_pre_intervention, data_post_intervention, alpha=0.05):\n",
    "\n",
    "    t_statitstic, p_value = stats.ttest_rel(data_pre_intervention, data_post_intervention)\n",
    "\n",
    "    mean_difference = np.mean(data_pre_intervention - data_post_intervention)\n",
    "    standard_difference = np.std(data_pre_intervention - data_post_intervention, ddof=1)\n",
    "    cohen_d = mean_difference / standard_difference\n",
    "\n",
    "    effect_size = np.abs(cohen_d)\n",
    "    n = len(data_pre_intervention)\n",
    "    power_analysis = TTestPower()\n",
    "    power = power_analysis.solve_power(effect_size=effect_size, nobs=n, alpha=alpha, alternative='two-sided')\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Metric': ['T-statistic', 'P-value', 'Effect Size (Cohen\\'s d)', 'Statistical Power'],\n",
    "        'Value': [t_statitstic, p_value, cohen_d, power]\n",
    "    })\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    data_pre_intervention = np.random.normal(100, 10, 30)\n",
    "    data_post_intervention = data_pre_intervention + np.random.normal(-3, 5, 30)\n",
    "\n",
    "    results = perform_dependent_sample_ttest(data_pre_intervention, data_post_intervention)\n",
    "\n",
    "    print(results.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eeab8e-06e9-4485-845d-a034a543223b",
   "metadata": {},
   "source": [
    "Note that this code does not even contain a single comment or any additional explanations. Simply from the way the variables were named, we can understand what it does much more quickly, almost like reading a text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913c441a-cead-458a-b35c-19dba296c2f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <u>2. **Code Structure**</u>\n",
    "\n",
    "- _Modularity_: Prioritize modular over monolithic structure.\n",
    "    - E.g., modular functions each perform a single task, making the code easier to read, test, and debug.\n",
    "- *Avoiding Nesting*: To enhance modularity, de-nesting code generally improves readability.\n",
    "    - Why? Nesting necessarily requires more working memory, as more information has to be held in mind before a chunk of operations comes to an end.\n",
    "    - How?\n",
    "        - *Extraction*: Pull out parts from the nested structure and make them into their own operations (e.g., two modular functions instead of one nesting the other).\n",
    "        - *Inversion*: De-nest conditional statements or loops by handling exceptional cases *at the beginning* instead of at the end. This allows the main logic later to be less nested and more easily readable.\n",
    "- A simple mental short-hand here is: Whenever *you yourself* feel like you have to hold too much in your mind when nesting operations *while working on the problem*, imagine how others will feel. That feeling in yourself is a valuable guide towards readability for others.\n",
    "\n",
    "For example, look at this code. I tried to make this as horrible as possible (maybe a bit too much so haha), but it illustrates the point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe994c5-a94e-4ef8-bc2b-8a56b2d03e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant difference between Data1 and Data2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.131054905179291, 0.8958649361982147)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = np.random.normal(0, 1, 100)\n",
    "data2 = np.random.normal(0.5, 1, 100)\n",
    "\n",
    "def t_test(data1, data2):\n",
    "    t_statistic = 0\n",
    "    p_value = 0\n",
    "    if len(data1) > 0:\n",
    "        if len(data2) > 0:\n",
    "            mean1 = 0\n",
    "            mean2 = 0\n",
    "            var1 = 0\n",
    "            var2 = 0\n",
    "            n1 = len(data1)\n",
    "            n2 = len(data2)\n",
    "            for i in range(n1):\n",
    "                for j in range(n2):\n",
    "                    if i == 0:\n",
    "                        mean1 += data1[i] / n1\n",
    "                    else:\n",
    "                        if j == 0:\n",
    "                            mean2 += data2[j] / n2\n",
    "                        else:\n",
    "                            var1 += (data1[i] - mean1) ** 2 / (n1 - 1)\n",
    "                            var2 += (data2[j] - mean2) ** 2 / (n2 - 1)\n",
    "                            if i == n1 - 1 and j == n2 - 1:\n",
    "                                pooled_var = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n",
    "                                if pooled_var != 0:\n",
    "                                    t_statistic = (mean1 - mean2) / np.sqrt(pooled_var * (1/n1 + 1/n2))\n",
    "                                    if t_statistic != 0:\n",
    "                                        p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df=n1 + n2 - 2))\n",
    "                                        if p_value < 0.05:\n",
    "                                            if t_statistic > 0:\n",
    "                                                print(\"Data1 mean is significantly greater than Data2 mean.\")\n",
    "                                            elif t_statistic < 0:\n",
    "                                                print(\"Data1 mean is significantly less than Data2 mean.\")\n",
    "                                            else:\n",
    "                                                print(\"Data1 mean is equal to Data2 mean.\")\n",
    "                                        else:\n",
    "                                            print(\"No significant difference between Data1 and Data2.\")\n",
    "                                    else:\n",
    "                                        print(\"t-statistic is zero, cannot determine significance.\")\n",
    "                                else:\n",
    "                                    print(\"Pooled variance is zero, cannot perform t-test.\")\n",
    "                            else:\n",
    "                                continue\n",
    "                        continue\n",
    "                continue\n",
    "        else:\n",
    "            print(\"Data2 is empty, cannot perform t-test.\")\n",
    "    else:\n",
    "        print(\"Data1 is empty, cannot perform t-test.\")\n",
    "    return t_statistic, p_value\n",
    "\n",
    "t_test(data1, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a285b-b82d-4d31-b461-7b9f9afecaf1",
   "metadata": {},
   "source": [
    "**Alternatively**, we could achieve the exact same result by _extracting_ the calculations and interpretations performed within the funcion to three modular functions, as well as _inverting_ the if-statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "529acb42-7137-4626-83ad-a5b8071b22c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data1 mean is significantly less than Data2 mean.\n",
      "(-2.4046746299230826, 0.017107691525127144)\n"
     ]
    }
   ],
   "source": [
    "data1 = np.random.normal(0, 1, 100)\n",
    "data2 = np.random.normal(0.5, 1, 100)\n",
    "\n",
    "def calculate_mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "def calculate_variance(data, mean):\n",
    "    return np.var(data, ddof=1)\n",
    "\n",
    "def perform_t_test(data1, data2):\n",
    "    if len(data1) == 0 or len(data2) == 0:\n",
    "        raise ValueError(\"Both data1 and data2 must contain data.\")\n",
    "\n",
    "    mean1 = calculate_mean(data1)\n",
    "    mean2 = calculate_mean(data2)\n",
    "\n",
    "    var1 = calculate_variance(data1, mean1)\n",
    "    var2 = calculate_variance(data2, mean2)\n",
    "\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "    pooled_var = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n",
    "\n",
    "    if pooled_var == 0:\n",
    "        raise ValueError(\"Pooled variance is zero, cannot perform t-test.\")\n",
    "\n",
    "    t_statistic = (mean1 - mean2) / np.sqrt(pooled_var * (1/n1 + 1/n2))\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_statistic), df=n1 + n2 - 2))\n",
    "\n",
    "    return t_statistic, p_value\n",
    "\n",
    "def interpret_results(t_statistic, p_value, alpha=0.05):\n",
    "    if p_value < alpha:\n",
    "        if t_statistic > 0:\n",
    "            return \"Data1 mean is significantly greater than Data2 mean.\"\n",
    "        elif t_statistic < 0:\n",
    "            return \"Data1 mean is significantly less than Data2 mean.\"\n",
    "        else:\n",
    "            return \"Data1 mean is equal to Data2 mean.\"\n",
    "    return \"No significant difference between Data1 and Data2.\"\n",
    "\n",
    "try:\n",
    "    t_stat, p_val = perform_t_test(data1, data2)\n",
    "    result = interpret_results(t_stat, p_val)\n",
    "    print(result)\n",
    "    print((t_stat, p_val))\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db219b33-239c-4055-979d-a875a07ebe2d",
   "metadata": {},
   "source": [
    "Also remember that the architecture of Jupyter Notebook allows chunks of code to be executed out of order (similar to R-Markdown for those who know that better). This can lead to the trap of never actually letting one's code run through from top to bottom. Thus, as a note to structure, try to _let the code run through end-to-end once in a while_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a955d85b-55be-4773-bef3-3292f464ecbb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <u>3. **Commenting and Documentation**</u>\r\n",
    "\r\n",
    "- In Jupyter Notebook, you have two levers for commenting and documenting the project: as comments within the code chunks or as markdown blocks between the code. We recommend dividing these two like so:\r\n",
    "    - The *markdown sections* should include primarily *conceptual* explanations for what is being done in the code. They should serve as “word equations,” explaining the ideas behind what is then implemented in code form.\r\n",
    "    - *Comments inside the code* itself should instead be *syntactical*, i.e., how *exactly* were the conceptual ideas of each section implemented as code? You should not feel the need to write novels in your comments. Instead, see if you can make your variable and function names, or your code structure in general, more readable.\r\n",
    "\r\n",
    "Let's look at the example from the dependent sample t-test from before (the one we used to specify variable naming). \r\n",
    "A synergy of markdown and code comments might look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9673469-2160-4383-9ae7-086a1135bc4e",
   "metadata": {},
   "source": [
    "_\"Since lack of power analysis was a major criticism that was made against the study regarding open science practice and reproducibility, we decided to compute effect size and subsequently power alongside the conventional t-statistic and p-value. \n",
    "Additionally, similarly to the study, we implemented a two-sided alpha-threshold and did not correct for multiple testing. We are aware of this statistical inadequacy, but attempted to replicate the procedure from the study accurately in this regard. \n",
    "Power, on the other side, only provides an additional statistical measure and does not directly influence any of the results, which is why we felt free to add it.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d0ec1904-ae45-4d35-915b-1475c2c5d3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Metric    Value\n",
      "            T-statistic 4.242251\n",
      "                P-value 0.000206\n",
      "Effect Size (Cohen's d) 0.774526\n",
      "      Statistical Power 0.983744\n"
     ]
    }
   ],
   "source": [
    "def perform_dependent_sample_ttest(data_pre_intervention, data_post_intervention):\n",
    "\n",
    "    t_statitstic, p_value = stats.ttest_rel(data_pre_intervention, data_post_intervention)\n",
    "\n",
    "    mean_difference = np.mean(data_pre_intervention - data_post_intervention) #Using the data from (source)\n",
    "    standard_difference = np.std(data_pre_intervention - data_post_intervention, ddof=1)\n",
    "    cohen_d = mean_difference / standard_difference\n",
    "\n",
    "    effect_size = np.abs(cohen_d) #Effect size for power-analysis\n",
    "    n = len(data_pre_intervention)\n",
    "    power_analysis = TTestPower() #Power: Was seen as major potential drawback in open science practice in main study\n",
    "    \n",
    "    #Decision to perform a two-sided t-test to better approximate approach in study\n",
    "    power = power_analysis.solve_power(effect_size=effect_size, nobs=n, alpha=0.05, alternative='two-sided')\n",
    "                                                                        #alpha of 0.05 since we did not perform multiple tests\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Metric': ['T-statistic', 'P-value', 'Effect Size (Cohen\\'s d)', 'Statistical Power'],\n",
    "        'Value': [t_statitstic, p_value, cohen_d, power]\n",
    "    })\n",
    "\n",
    "    return results\n",
    "    \n",
    "def main():\n",
    "    np.random.seed(42)\n",
    "    data_pre_intervention = np.random.normal(100, 10, 30)\n",
    "    data_post_intervention = data_pre_intervention + np.random.normal(-3, 5, 30)\n",
    "\n",
    "    results = perform_dependent_sample_ttest(data_pre_intervention, data_post_intervention)\n",
    "\n",
    "    print(results.to_string(index=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb91de64-8e04-48e2-9572-a1b020b02ce1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### <u>4. **Error Handling, Logging, Print Statements**</u>\r\n",
    "\r\n",
    "- If an _error_ is raised, where to make a fix should be instantly identifiable in the code.\r\n",
    "    - Implement error handling by _anticipating possible failure points_. If you implement an idea in code intentionally, it should be intuitive to you where things may go wrong. Use exceptions judiciously and ensure they are informative.\r\n",
    "- _Logging/print statements_ are particularly important in our use case since we are trying to build a long-form pipeline where frequent updates of the processing stage are useful. However, since we are mainly working with Jupyter Notebook, i.e., small, self-contained chunks, this should also not become too verbose. Logs or print statements should be _targeted and intentional_, providing the detail needed to diagnose an issue quickly or figure out generally where one is in the processes.\r\n",
    "\r\n",
    "Again, let us look at two examples. The first one uses logging and print statements verbosely and unnecessarily. This just clutters the script without providing the user with much information for potential fixes or useful knowledge on the overall process. \r\n",
    "Note that each of these logs and print statements, if used with intent, is potentially meaningful. But just throwing them in arbitrarily should be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e463e6d1-9ab7-4555-8c2c-472b58702dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data received. Lengths: 5 and 5\n",
      "p-value is not None: 0.36827250552188723\n",
      "t-statistic: -0.9534625892455922\n",
      "p-value: 0.36827250552188723\n",
      "The result is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Setting up logging\n",
    "logging.basicConfig(filename='app.log', level=logging.INFO)\n",
    "\n",
    "def perform_t_test(data1, data2):\n",
    "    try:\n",
    "        if not isinstance(data1, list) or not isinstance(data2, list):\n",
    "            logging.error(\"One of the inputs is not a list\")\n",
    "            print(\"Error: Inputs should be lists.\")\n",
    "            return\n",
    "        \n",
    "        if len(data1) == 0 or len(data2) == 0:\n",
    "            logging.warning(\"One of the data lists is empty\")\n",
    "            print(\"Warning: One of the data lists is empty.\")\n",
    "            return\n",
    "        \n",
    "        print(\"Data received. Lengths:\", len(data1), \"and\", len(data2))\n",
    "        \n",
    "        # Perform the t-test\n",
    "        t_stat, p_value = ttest_ind(data1, data2)\n",
    "        \n",
    "        logging.info(f\"t_stat: {t_stat}, p_value: {p_value}\")\n",
    "        \n",
    "        if p_value is not None:\n",
    "            print(f\"p-value is not None: {p_value}\")\n",
    "        else:\n",
    "            print(\"p-value is None. This should not happen.\")\n",
    "\n",
    "        print(f\"t-statistic: {t_stat}\")\n",
    "        print(f\"p-value: {p_value}\")\n",
    "\n",
    "        if p_value < 0.05:\n",
    "            print(\"The result is statistically significant!\")\n",
    "        else:\n",
    "            print(\"The result is not statistically significant.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "data1 = [1.2, 2.3, 3.1, 4.4, 5.5]\n",
    "data2 = [2.3, 3.4, 4.1, 5.2, 6.5]\n",
    "perform_t_test(data1, data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c0fb11-586d-48bb-8632-2abfbeb03e67",
   "metadata": {},
   "source": [
    "In this example, however, we may be worried, for some reason, that our inputs is not a list as the function requires and are only interested in the significance of the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c99e2ef0-8ba4-4228-8a54-d61a1fb5a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "# Setting up logging\n",
    "logging.basicConfig(filename='app.log', level=logging.INFO)\n",
    "\n",
    "def perform_t_test(data1, data2):\n",
    "    try:\n",
    "        if not isinstance(data1, list) or not isinstance(data2, list):\n",
    "            logging.error(\"One of the inputs is not a list\")\n",
    "            return\n",
    "        \n",
    "        # Perform the t-test\n",
    "        t_stat, p_value = ttest_ind(data1, data2)\n",
    "        \n",
    "        if p_value < 0.05:\n",
    "            print(\"The result is statistically significant!\")\n",
    "        else:\n",
    "            print(\"The result is not statistically significant.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "data1 = [1.2, 2.3, 3.1, 4.4, 5.5]\n",
    "data2 = [2.3, 3.4, 4.1, 5.2, 6.5]\n",
    "perform_t_test(data1, data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f455c6a-7405-440e-91c4-00ecde64be37",
   "metadata": {},
   "source": [
    "This fourth point is perhaps the most controversial in our guidelines. Some people are very fond of extensive output to the user in their scripts. However, what we want to avoid with this is simply the generation of _too much unintentional code_. Please use logging or print statements whenever you feel it necessary. But most of us have probably been in the situation where we wished we had asked ourselves if a particular implementation was actually necessary _before_ writing it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52b41b0-31db-4ad6-8865-e8b1abb63c83",
   "metadata": {},
   "source": [
    "## Summary and Conclusion\n",
    "- Let’s end with a brief breakdown of the concrete actionables:\n",
    "  \n",
    "### Open Science:\n",
    "- Open Science starts with Open Ignorance: _Feel free to ask every question you may have!_\n",
    "- Indicate where _you_ have contributed to the project to facilitate effective communication and credit where it is due.\n",
    "- Freely share ideas and findings within and across teams.\n",
    "- Transparently refer to external resources that you use, such as papers or AI.\n",
    "- Report _everything_ you find and document your decisions for or against certain approaches comprehensibly.\n",
    "- Try to use the digital ReprodICUbility infrastructure, which is organized to support open science by design.\n",
    "\n",
    "### Coding Guidelines:\n",
    "- Being able to quickly understand one another’s code is essential in this project: try to follow the _standards_ and aim for _readability_.\n",
    "- Name variables and functions _explicitly_. Try not to use abbreviations and provide more detail rather than less (err on the side of “too obvious”).\n",
    "- Prioritize modularity and _avoid nesting_. Implement extraction and inversion to separate the code into easily readable and debuggable chunks.\n",
    "- Use the markdown sections to explain your approach _conceptually_ and comments in code blocks to localize the concepts in concrete _syntax_.\n",
    "- Generally: try coding with _intent_. Code is, after all, a _tool_ — there to implement specific ideas. This applies, for example, to _error handling and logging/print statements_. Use them with purpose to bolster specific, potential weak points or highlight important steps in the process.\n",
    "- Our project runs the risk of producing a lot of code very quickly. This is natural in such a large multi-team endeavour, but ideally we avoid losing the thread in tangled thickets of untargeted, untraceable code.\n",
    "\n",
    "Interesting Resource:  \n",
    "Jackson Z. Code Is for Humans: A Guide to Human-Centric Software Engineering. Independently published; 2024 Mar 19. ISBN-13: 9798861816489.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
